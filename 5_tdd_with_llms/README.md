# Test-Driven Development with Large Language Models

Large Language Models (LLMs) can generate lots of (mostly) working code very
quickly. If you're not careful, LLMs can make you a sloppy programmer and slow
down your progress in the long run. If you use LLMs carefully, you can learn
more quickly and become a more efficient developer. This workshop covers one
strategy for collaborating with LLMs to go from a blank page to finished code
that is readable, documented, and well-tested.

- [Learning Objectives](#learning-objectives)
- [Test-Driven Development](./test_driven_development.md)
- [CoAIthoring Workflow](./coaithoring_workflow.md)
- [Prep Work](./prep_work.md)
- [Lesson Plan](./lesson_plan.md)

---

## Learning Objectives

<details><summary>Priorities: ğŸ¥šğŸ£ğŸ¥ğŸ” (click for more info)</summary>
<br />

Learning objectives for this workshop are labeled so you can prioritize your
study time. The emojis show the _minimum_ mastery you are expected to achieve
for each skill, but there is no maximum! If you have the time you should aim to
master all of the skills introduced in this workshop.

- ğŸ¥š You are expected to master these skills. They are the foundations you will
  need to move forward.
- ğŸ£ You are expected to be comfortable with these skills. It's ok if you still
  need help sometimes.
- ğŸ¥ You are expected to be familiar with these skills. It's enough to recognize
  them in practice and apply them with help.
- ğŸ” You are not expected to know these skills, but they are important if you
  want to excel. You should only focus on these after mastering the ğŸ¥š, ğŸ£ and
  ğŸ¥ objectives.

---

</details>

### TDD with LLMs

- ğŸ¥š You can translate an open-ended problem into a complete docstring.
- ğŸ¥š You can use an LLM to generate code by providing a clear prompt and code
  for context.
- ğŸ¥š You can comment, understand and review code generated by an LLM, judging if
  it is correct or not.
- ğŸ¥š You run your unit tests every time you make any change to your function,
  making sure they still pass.
- ğŸ¥š Every time you want to change a function's behavior, you first update the
  tests before changing the function.
- ğŸ£ When a test fails, you can determine if it was the test or the function
  that is not correct.
- ğŸ£ You can collaborate with an LLM to find and fix bugs in your code.
- ğŸ£ You can collaborate with an LLM to _refactor_ a program's strategy or
  implementation without modifying its behavior.
- ğŸ£ You can polish and personalize your final code to showcase your
  understanding instead of just another program generated from an LLM.

### Situating LLMs

- ğŸ¥š You are aware of concerns that LLMs may generate responses in violation of
  copyright law, or that violate data privacy.
- ğŸ¥š You are aware that training and running LLMs
  [consumes more energy](https://ai.stackexchange.com/questions/38970/how-much-energy-consumption-is-involved-in-chat-gpt-responses-being-generated)
  than older tools like [internet search](https://arxiv.org/pdf/2307.01135.pdf).
- ğŸ¥š You are aware that LLMs can _hallucinate_ - they can produce responses that
  feel correct but are actually untrue.
- ğŸ¥š You are aware that LLMs can, despite many guardrails, produce responses
  that perpetuate stereotypes and misconceptions.

### Non-Objective: Prompt Engineering

This workshop does not cover _prompt engineering_: how to carefully construct
sentences and questions for the LLM to get better results. Prompt engineering is
a whole topic of it's own. You can learn more about it online by following
[tutorials](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/),
reading [articles](https://en.wikipedia.org/wiki/Prompt_engineering), and
[practicing](https://phind.com/).

Instead we will zoom out from specific LLM prompts and focus on how you can
integrate LLMs into your development workflow.
